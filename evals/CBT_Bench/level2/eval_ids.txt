EvalCreateResponse(id='eval_68d2fa38ed6c8191abadb896f9d861bf', created_at=1758657080, data_source_config=EvalCustomDataSourceConfig(schema_={'type': 'object', 'properties': {'item': {'type': 'object', 'properties': {'id': {'type': 'string'}, 'ori_text': {'type': 'string'}, 'situation': {'type': 'string'}, 'thoughts': {'type': 'string'}, 'distortions': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['id', 'ori_text', 'situation', 'thoughts', 'distortions']}, 'sample': {'type': 'object', 'properties': {'model': {'type': 'string'}, 'choices': {'type': 'array', 'items': {'type': 'object', 'properties': {'message': {'type': 'object', 'properties': {'role': {'type': 'string', 'enum': ['assistant']}, 'content': {'type': ['string', 'array', 'null']}, 'refusal': {'type': ['boolean', 'null']}, 'tool_calls': {'type': ['array', 'null'], 'items': {'type': 'object', 'properties': {'type': {'type': 'string', 'enum': ['function']}, 'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}, 'id': {'type': 'string'}}, 'required': ['type', 'function', 'id']}}, 'function_call': {'type': ['object', 'null'], 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}}, 'required': ['role']}, 'finish_reason': {'type': 'string'}}, 'required': ['index', 'message', 'finish_reason']}}, 'output_text': {'type': 'string'}, 'output_json': {'type': 'object'}, 'output_tools': {'type': 'array', 'items': {'type': 'object'}}, 'output_reasoning_summary': {'type': ['string', 'null']}, 'output_audio': {'type': ['object', 'null']}, 'input_tools': {'type': 'array', 'items': {'type': 'object'}}}, 'required': ['model', 'choices']}}, 'required': ['item', 'sample']}, type='custom', max_items=None), metadata={}, name='CBT Bench Distortions Test', object='eval', testing_criteria=[StringCheckGrader(input='{{ sample.output_text }}', name='Match output to human label', operation='eq', reference='{{ item.distortions }}', type='string_check', id='Match output to human label-1e66c54a-3d97-45aa-a105-cc16bd944908', inactive_at=None)])
EvalCreateResponse(id='eval_68d9829e4f008191923354e6e632ac49', created_at=1759085214, data_source_config=EvalCustomDataSourceConfig(schema_={'type': 'object', 'properties': {'item': {'type': 'object', 'properties': {'id': {'type': 'string'}, 'ori_text': {'type': 'string'}, 'situation': {'type': 'string'}, 'thoughts': {'type': 'string'}, 'distortions': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['id', 'ori_text', 'situation', 'thoughts', 'distortions']}, 'sample': {'type': 'object', 'properties': {'model': {'type': 'string'}, 'choices': {'type': 'array', 'items': {'type': 'object', 'properties': {'message': {'type': 'object', 'properties': {'role': {'type': 'string', 'enum': ['assistant']}, 'content': {'type': ['string', 'array', 'null']}, 'refusal': {'type': ['boolean', 'null']}, 'tool_calls': {'type': ['array', 'null'], 'items': {'type': 'object', 'properties': {'type': {'type': 'string', 'enum': ['function']}, 'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}, 'id': {'type': 'string'}}, 'required': ['type', 'function', 'id']}}, 'function_call': {'type': ['object', 'null'], 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}}, 'required': ['role']}, 'finish_reason': {'type': 'string'}}, 'required': ['index', 'message', 'finish_reason']}}, 'output_text': {'type': 'string'}, 'output_json': {'type': 'object'}, 'output_tools': {'type': 'array', 'items': {'type': 'object'}}, 'output_reasoning_summary': {'type': ['string', 'null']}, 'output_audio': {'type': ['object', 'null']}, 'input_tools': {'type': 'array', 'items': {'type': 'object'}}}, 'required': ['model', 'choices']}}, 'required': ['item', 'sample']}, type='custom', max_items=None), metadata={}, name='CBT Bench Distortions Test', object='eval', testing_criteria=[TestingCriterionEvalGraderPython(name='precision', source='\nfrom typing import Any\n\ndef grade(sample, item) -> float:\n    output_labels = sample["output_text"]\n    truth_labels = item["distortions"]\n\n    if not output_labels == 0:\n        return 0.0\n\n    correct = 0.0\n    for label in output_labels:\n        if label in truth_labels:\n            correct += 1.0\n    \n    return correct/len(output_labels)\n              ', type='python', image_tag='2025-05-08', pass_threshold=None, id='precision-f16798fc-920e-45f8-8e61-a7e426451cba', inactive_at=None)])
EvalCreateResponse(id='eval_68d982deabcc819189dec6320c2d91bc', created_at=1759085278, data_source_config=EvalCustomDataSourceConfig(schema_={'type': 'object', 'properties': {'item': {'type': 'object', 'properties': {'id': {'type': 'string'}, 'ori_text': {'type': 'string'}, 'situation': {'type': 'string'}, 'thoughts': {'type': 'string'}, 'distortions': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['id', 'ori_text', 'situation', 'thoughts', 'distortions']}, 'sample': {'type': 'object', 'properties': {'model': {'type': 'string'}, 'choices': {'type': 'array', 'items': {'type': 'object', 'properties': {'message': {'type': 'object', 'properties': {'role': {'type': 'string', 'enum': ['assistant']}, 'content': {'type': ['string', 'array', 'null']}, 'refusal': {'type': ['boolean', 'null']}, 'tool_calls': {'type': ['array', 'null'], 'items': {'type': 'object', 'properties': {'type': {'type': 'string', 'enum': ['function']}, 'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}, 'id': {'type': 'string'}}, 'required': ['type', 'function', 'id']}}, 'function_call': {'type': ['object', 'null'], 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}}, 'required': ['role']}, 'finish_reason': {'type': 'string'}}, 'required': ['index', 'message', 'finish_reason']}}, 'output_text': {'type': 'string'}, 'output_json': {'type': 'object'}, 'output_tools': {'type': 'array', 'items': {'type': 'object'}}, 'output_reasoning_summary': {'type': ['string', 'null']}, 'output_audio': {'type': ['object', 'null']}, 'input_tools': {'type': 'array', 'items': {'type': 'object'}}}, 'required': ['model', 'choices']}}, 'required': ['item', 'sample']}, type='custom', max_items=None), metadata={}, name='CBT Bench Distortions Test', object='eval', testing_criteria=[TestingCriterionEvalGraderPython(name='precision', source='\nfrom typing import Any\n\ndef grade(sample, item) -> float:\n    output_labels = sample["output_text"]\n    truth_labels = item["distortions"]\n\n    if not output_labels == 0:\n        return 0.0\n\n    correct = 0.0\n    for label in output_labels:\n        if label in truth_labels:\n            correct += 1.0\n    \n    return correct/len(output_labels)\n              ', type='python', image_tag='2025-05-08', pass_threshold=None, id='precision-b2f35350-2055-4081-abc2-8694ba493551', inactive_at=None)])
EvalCreateResponse(id='eval_68d986ea645c8191aadd19e3c94d661c', created_at=1759086314, data_source_config=EvalCustomDataSourceConfig(schema_={'type': 'object', 'properties': {'item': {'type': 'object', 'properties': {'id': {'type': 'string'}, 'ori_text': {'type': 'string'}, 'situation': {'type': 'string'}, 'thoughts': {'type': 'string'}, 'distortions': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['id', 'ori_text', 'situation', 'thoughts', 'distortions']}, 'sample': {'type': 'object', 'properties': {'model': {'type': 'string'}, 'choices': {'type': 'array', 'items': {'type': 'object', 'properties': {'message': {'type': 'object', 'properties': {'role': {'type': 'string', 'enum': ['assistant']}, 'content': {'type': ['string', 'array', 'null']}, 'refusal': {'type': ['boolean', 'null']}, 'tool_calls': {'type': ['array', 'null'], 'items': {'type': 'object', 'properties': {'type': {'type': 'string', 'enum': ['function']}, 'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}, 'id': {'type': 'string'}}, 'required': ['type', 'function', 'id']}}, 'function_call': {'type': ['object', 'null'], 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}}, 'required': ['role']}, 'finish_reason': {'type': 'string'}}, 'required': ['index', 'message', 'finish_reason']}}, 'output_text': {'type': 'string'}, 'output_json': {'type': 'object'}, 'output_tools': {'type': 'array', 'items': {'type': 'object'}}, 'output_reasoning_summary': {'type': ['string', 'null']}, 'output_audio': {'type': ['object', 'null']}, 'input_tools': {'type': 'array', 'items': {'type': 'object'}}}, 'required': ['model', 'choices']}}, 'required': ['item', 'sample']}, type='custom', max_items=None), metadata={}, name='CBT Bench Distortions Test', object='eval', testing_criteria=[TestingCriterionEvalGraderPython(name='precision', source='\nfrom typing import Any\nimport json\n\ndef grade(sample, item) -> float:\n    output_labels = json.loads(sample["output_text"])\n    truth_labels = item["distortions"]\n\n    if not output_labels == 0:\n        return 0.0\n\n    correct = 0.0\n    for label in output_labels:\n        if label in truth_labels:\n            correct += 1.0\n    \n    return correct/len(output_labels)\n              ', type='python', image_tag='2025-05-08', pass_threshold=None, id='precision-37f21827-9ae7-434b-b64d-0ce7e473b050', inactive_at=None)])
EvalCreateResponse(id='eval_68d987bc59748191a45464708db3ef80', created_at=1759086524, data_source_config=EvalCustomDataSourceConfig(schema_={'type': 'object', 'properties': {'item': {'type': 'object', 'properties': {'id': {'type': 'string'}, 'ori_text': {'type': 'string'}, 'situation': {'type': 'string'}, 'thoughts': {'type': 'string'}, 'distortions': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['id', 'ori_text', 'situation', 'thoughts', 'distortions']}, 'sample': {'type': 'object', 'properties': {'model': {'type': 'string'}, 'choices': {'type': 'array', 'items': {'type': 'object', 'properties': {'message': {'type': 'object', 'properties': {'role': {'type': 'string', 'enum': ['assistant']}, 'content': {'type': ['string', 'array', 'null']}, 'refusal': {'type': ['boolean', 'null']}, 'tool_calls': {'type': ['array', 'null'], 'items': {'type': 'object', 'properties': {'type': {'type': 'string', 'enum': ['function']}, 'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}, 'id': {'type': 'string'}}, 'required': ['type', 'function', 'id']}}, 'function_call': {'type': ['object', 'null'], 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}}, 'required': ['role']}, 'finish_reason': {'type': 'string'}}, 'required': ['index', 'message', 'finish_reason']}}, 'output_text': {'type': 'string'}, 'output_json': {'type': 'object'}, 'output_tools': {'type': 'array', 'items': {'type': 'object'}}, 'output_reasoning_summary': {'type': ['string', 'null']}, 'output_audio': {'type': ['object', 'null']}, 'input_tools': {'type': 'array', 'items': {'type': 'object'}}}, 'required': ['model', 'choices']}}, 'required': ['item', 'sample']}, type='custom', max_items=None), metadata={}, name='CBT Bench Distortions Test', object='eval', testing_criteria=[TestingCriterionEvalGraderPython(name='precision', source='\nfrom typing import Any\nimport json\n\ndef grade(sample, item) -> float:\n    output_labels = json.loads(sample["output_text"])\n    truth_labels = item["distortions"]\n\n    if not output_labels == 0:\n        return 0.0\n\n    correct = 0.0\n    for label in output_labels:\n        if label in truth_labels:\n            correct += 1.0\n    \n    return correct/len(output_labels)\n              ', type='python', image_tag='2025-05-08', pass_threshold=0.5, id='precision-317ec190-a4da-425e-b909-76073390c78f', inactive_at=None)])
EvalCreateResponse(id='eval_68d98a2ab5708191a29a6e46ea816d15', created_at=1759087146, data_source_config=EvalCustomDataSourceConfig(schema_={'type': 'object', 'properties': {'item': {'type': 'object', 'properties': {'id': {'type': 'string'}, 'ori_text': {'type': 'string'}, 'situation': {'type': 'string'}, 'thoughts': {'type': 'string'}, 'distortions': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['id', 'ori_text', 'situation', 'thoughts', 'distortions']}, 'sample': {'type': 'object', 'properties': {'model': {'type': 'string'}, 'choices': {'type': 'array', 'items': {'type': 'object', 'properties': {'message': {'type': 'object', 'properties': {'role': {'type': 'string', 'enum': ['assistant']}, 'content': {'type': ['string', 'array', 'null']}, 'refusal': {'type': ['boolean', 'null']}, 'tool_calls': {'type': ['array', 'null'], 'items': {'type': 'object', 'properties': {'type': {'type': 'string', 'enum': ['function']}, 'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}, 'id': {'type': 'string'}}, 'required': ['type', 'function', 'id']}}, 'function_call': {'type': ['object', 'null'], 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}}, 'required': ['role']}, 'finish_reason': {'type': 'string'}}, 'required': ['index', 'message', 'finish_reason']}}, 'output_text': {'type': 'string'}, 'output_json': {'type': 'object'}, 'output_tools': {'type': 'array', 'items': {'type': 'object'}}, 'output_reasoning_summary': {'type': ['string', 'null']}, 'output_audio': {'type': ['object', 'null']}, 'input_tools': {'type': 'array', 'items': {'type': 'object'}}}, 'required': ['model', 'choices']}}, 'required': ['item', 'sample']}, type='custom', max_items=None), metadata={}, name='CBT Bench Distortions Test', object='eval', testing_criteria=[TestingCriterionEvalGraderPython(name='precision', source='\nfrom typing import Any\nimport json\n\ndef grade(sample, item) -> float:\n    output_labels = json.loads(sample["output_text"])\n    truth_labels = item["distortions"]\n\n    if not output_labels == 0:\n        return 0.75\n\n    correct = 0.0\n    for label in output_labels:\n        if label in truth_labels:\n            correct += 1.0\n    \n    return correct/len(output_labels)\n              ', type='python', image_tag='2025-05-08', pass_threshold=0.5, id='precision-a1bee6cd-8ff0-479f-b447-56bb546bea32', inactive_at=None)])
EvalCreateResponse(id='eval_68d98ad190bc8191917f3f82bb95e61b', created_at=1759087313, data_source_config=EvalCustomDataSourceConfig(schema_={'type': 'object', 'properties': {'item': {'type': 'object', 'properties': {'id': {'type': 'string'}, 'ori_text': {'type': 'string'}, 'situation': {'type': 'string'}, 'thoughts': {'type': 'string'}, 'distortions': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['id', 'ori_text', 'situation', 'thoughts', 'distortions']}, 'sample': {'type': 'object', 'properties': {'model': {'type': 'string'}, 'choices': {'type': 'array', 'items': {'type': 'object', 'properties': {'message': {'type': 'object', 'properties': {'role': {'type': 'string', 'enum': ['assistant']}, 'content': {'type': ['string', 'array', 'null']}, 'refusal': {'type': ['boolean', 'null']}, 'tool_calls': {'type': ['array', 'null'], 'items': {'type': 'object', 'properties': {'type': {'type': 'string', 'enum': ['function']}, 'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}, 'id': {'type': 'string'}}, 'required': ['type', 'function', 'id']}}, 'function_call': {'type': ['object', 'null'], 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}}, 'required': ['role']}, 'finish_reason': {'type': 'string'}}, 'required': ['index', 'message', 'finish_reason']}}, 'output_text': {'type': 'string'}, 'output_json': {'type': 'object'}, 'output_tools': {'type': 'array', 'items': {'type': 'object'}}, 'output_reasoning_summary': {'type': ['string', 'null']}, 'output_audio': {'type': ['object', 'null']}, 'input_tools': {'type': 'array', 'items': {'type': 'object'}}}, 'required': ['model', 'choices']}}, 'required': ['item', 'sample']}, type='custom', max_items=None), metadata={}, name='CBT Bench Distortions Test', object='eval', testing_criteria=[TestingCriterionEvalGraderPython(name='precision', source='\nfrom typing import Any\nimport json\n\ndef grade(sample, item) -> float:\n    output_labels = json.loads(sample["output_text"])\n    truth_labels = item["distortions"]\n\n    if len(output_labels) == 0:\n        return 0.0\n\n    correct = 0.0\n    for label in output_labels:\n        if label in truth_labels:\n            correct += 1.0\n    \n    return correct/len(output_labels)\n              ', type='python', image_tag='2025-05-08', pass_threshold=0.5, id='precision-77aa625f-d2f1-47fd-b8db-2ccbcc6b2356', inactive_at=None)])
EvalCreateResponse(id='eval_68d98d91cadc81919245061c91c73053', created_at=1759088017, data_source_config=EvalCustomDataSourceConfig(schema_={'type': 'object', 'properties': {'item': {'type': 'object', 'properties': {'id': {'type': 'string'}, 'ori_text': {'type': 'string'}, 'situation': {'type': 'string'}, 'thoughts': {'type': 'string'}, 'distortions': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['id', 'ori_text', 'situation', 'thoughts', 'distortions']}, 'sample': {'type': 'object', 'properties': {'model': {'type': 'string'}, 'choices': {'type': 'array', 'items': {'type': 'object', 'properties': {'message': {'type': 'object', 'properties': {'role': {'type': 'string', 'enum': ['assistant']}, 'content': {'type': ['string', 'array', 'null']}, 'refusal': {'type': ['boolean', 'null']}, 'tool_calls': {'type': ['array', 'null'], 'items': {'type': 'object', 'properties': {'type': {'type': 'string', 'enum': ['function']}, 'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}, 'id': {'type': 'string'}}, 'required': ['type', 'function', 'id']}}, 'function_call': {'type': ['object', 'null'], 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}}, 'required': ['role']}, 'finish_reason': {'type': 'string'}}, 'required': ['index', 'message', 'finish_reason']}}, 'output_text': {'type': 'string'}, 'output_json': {'type': 'object'}, 'output_tools': {'type': 'array', 'items': {'type': 'object'}}, 'output_reasoning_summary': {'type': ['string', 'null']}, 'output_audio': {'type': ['object', 'null']}, 'input_tools': {'type': 'array', 'items': {'type': 'object'}}}, 'required': ['model', 'choices']}}, 'required': ['item', 'sample']}, type='custom', max_items=None), metadata={}, name='CBT Bench Distortions Test - Precision and Recall', object='eval', testing_criteria=[TestingCriterionEvalGraderPython(name='precision', source='\nfrom typing import Any\nimport json\n\ndef grade(sample, item) -> float:\n    output_labels = json.loads(sample["output_text"])\n    truth_labels = item["distortions"]\n\n    if len(output_labels) == 0:\n        return 0.0\n\n    correct = 0.0\n    for label in output_labels:\n        if label in truth_labels:\n            correct += 1.0\n    \n    return correct/len(output_labels)\n              ', type='python', image_tag='2025-05-08', pass_threshold=0.5, id='precision-e90ce08e-8396-49e6-8475-ed0736e27e48', inactive_at=None), TestingCriterionEvalGraderPython(name='recall', source='\nfrom typing import Any\nimport json\n\ndef grade(sample, item) -> float:\n    output_labels = json.loads(sample["output_text"])\n    truth_labels = item["distortions"]\n\n    if len(output_labels) == 0:\n        return 0.0\n\n    correct = 0.0\n    for label in output_labels:\n        if label in truth_labels:\n            correct += 1.0\n    \n    return correct/len(truth_labels)\n              ', type='python', image_tag='2025-05-08', pass_threshold=0.5, id='recall-884dd7ad-1c4b-473e-8d31-7dfa20baacc4', inactive_at=None)])
EvalCreateResponse(id='eval_68d9956154c88191a89b4491671d3310', created_at=1759090017, data_source_config=EvalCustomDataSourceConfig(schema_={'type': 'object', 'properties': {'item': {'type': 'object', 'properties': {'id': {'type': 'string'}, 'ori_text': {'type': 'string'}, 'situation': {'type': 'string'}, 'thoughts': {'type': 'string'}, 'core_belief_major': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['id', 'ori_text', 'situation', 'thoughts', 'core_belief_major']}, 'sample': {'type': 'object', 'properties': {'model': {'type': 'string'}, 'choices': {'type': 'array', 'items': {'type': 'object', 'properties': {'message': {'type': 'object', 'properties': {'role': {'type': 'string', 'enum': ['assistant']}, 'content': {'type': ['string', 'array', 'null']}, 'refusal': {'type': ['boolean', 'null']}, 'tool_calls': {'type': ['array', 'null'], 'items': {'type': 'object', 'properties': {'type': {'type': 'string', 'enum': ['function']}, 'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}, 'id': {'type': 'string'}}, 'required': ['type', 'function', 'id']}}, 'function_call': {'type': ['object', 'null'], 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}}, 'required': ['role']}, 'finish_reason': {'type': 'string'}}, 'required': ['index', 'message', 'finish_reason']}}, 'output_text': {'type': 'string'}, 'output_json': {'type': 'object'}, 'output_tools': {'type': 'array', 'items': {'type': 'object'}}, 'output_reasoning_summary': {'type': ['string', 'null']}, 'output_audio': {'type': ['object', 'null']}, 'input_tools': {'type': 'array', 'items': {'type': 'object'}}}, 'required': ['model', 'choices']}}, 'required': ['item', 'sample']}, type='custom', max_items=None), metadata={}, name='CBT Bench Core Perosonal Belief Test - Precision and Recall', object='eval', testing_criteria=[TestingCriterionEvalGraderPython(name='precision', source='\nfrom typing import Any\nimport json\n\ndef grade(sample, item) -> float:\n    output_labels = json.loads(sample["output_text"])\n    truth_labels = item["core_belief_major"]\n\n    if len(output_labels) == 0:\n        return 0.0\n\n    correct = 0.0\n    for label in output_labels:\n        if label in truth_labels:\n            correct += 1.0\n    \n    return correct/len(output_labels)\n              ', type='python', image_tag='2025-05-08', pass_threshold=0.5, id='precision-a9b60c55-aacc-4d0e-a572-ee57576e3636', inactive_at=None), TestingCriterionEvalGraderPython(name='recall', source='\nfrom typing import Any\nimport json\n\ndef grade(sample, item) -> float:\n    output_labels = json.loads(sample["output_text"])\n    truth_labels = item["core_belief_major"]\n\n    if len(output_labels) == 0:\n        return 0.0\n\n    correct = 0.0\n    for label in output_labels:\n        if label in truth_labels:\n            correct += 1.0\n    \n    return correct/len(truth_labels)\n              ', type='python', image_tag='2025-05-08', pass_threshold=0.5, id='recall-44bb4344-20be-4b80-94c1-23be56a2b895', inactive_at=None)])
EvalCreateResponse(id='eval_68d99dbe17e48191ac51902a80e028a7', created_at=1759092158, data_source_config=EvalCustomDataSourceConfig(schema_={'type': 'object', 'properties': {'item': {'type': 'object', 'properties': {'id': {'type': 'string'}, 'ori_text': {'type': 'string'}, 'situation': {'type': 'string'}, 'thoughts': {'type': 'string'}, 'core_belief_fine_grained': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['id', 'ori_text', 'situation', 'thoughts', 'core_belief_fine_grained']}, 'sample': {'type': 'object', 'properties': {'model': {'type': 'string'}, 'choices': {'type': 'array', 'items': {'type': 'object', 'properties': {'message': {'type': 'object', 'properties': {'role': {'type': 'string', 'enum': ['assistant']}, 'content': {'type': ['string', 'array', 'null']}, 'refusal': {'type': ['boolean', 'null']}, 'tool_calls': {'type': ['array', 'null'], 'items': {'type': 'object', 'properties': {'type': {'type': 'string', 'enum': ['function']}, 'function': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}, 'id': {'type': 'string'}}, 'required': ['type', 'function', 'id']}}, 'function_call': {'type': ['object', 'null'], 'properties': {'name': {'type': 'string'}, 'arguments': {'type': 'string'}}, 'required': ['name', 'arguments']}}, 'required': ['role']}, 'finish_reason': {'type': 'string'}}, 'required': ['index', 'message', 'finish_reason']}}, 'output_text': {'type': 'string'}, 'output_json': {'type': 'object'}, 'output_tools': {'type': 'array', 'items': {'type': 'object'}}, 'output_reasoning_summary': {'type': ['string', 'null']}, 'output_audio': {'type': ['object', 'null']}, 'input_tools': {'type': 'array', 'items': {'type': 'object'}}}, 'required': ['model', 'choices']}}, 'required': ['item', 'sample']}, type='custom', max_items=None), metadata={}, name='CBT Bench Fine Perosonal Belief Test - Precision and Recall', object='eval', testing_criteria=[TestingCriterionEvalGraderPython(name='precision', source='\nfrom typing import Any\nimport json\n\ndef grade(sample, item) -> float:\n    output_labels = json.loads(sample["output_text"])\n    truth_labels = item["core_belief_fine_grained"]\n\n    if len(output_labels) == 0:\n        return 0.0\n\n    correct = 0.0\n    for label in output_labels:\n        if label in truth_labels:\n            correct += 1.0\n    \n    return correct/len(output_labels)\n              ', type='python', image_tag='2025-05-08', pass_threshold=0.5, id='precision-6d82c852-aeb8-4cbe-bac0-3b20b6064f9a', inactive_at=None), TestingCriterionEvalGraderPython(name='recall', source='\nfrom typing import Any\nimport json\n\ndef grade(sample, item) -> float:\n    output_labels = json.loads(sample["output_text"])\n    truth_labels = item["core_belief_fine_grained"]\n\n    if len(output_labels) == 0:\n        return 0.0\n\n    correct = 0.0\n    for label in output_labels:\n        if label in truth_labels:\n            correct += 1.0\n    \n    return correct/len(truth_labels)\n              ', type='python', image_tag='2025-05-08', pass_threshold=0.5, id='recall-51b2be65-70e9-4d3a-9fdb-96e574fdd138', inactive_at=None)])
